{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872f055c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>11365</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Blue State in a red sea</td>\n",
       "      <td>Media should have warned us well in advance. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11366</th>\n",
       "      <td>11366</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>arohaonces</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>11367</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>ðŸ‡µðŸ‡­</td>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>11368</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>auroraborealis</td>\n",
       "      <td>ok who remember \"outcast\" nd the \"dora\" au?? T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>11369</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake Corway wrecked while running 14th at IRP.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11370 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  keyword                 location  \\\n",
       "0          0   ablaze                      NaN   \n",
       "1          1   ablaze                      NaN   \n",
       "2          2   ablaze            New York City   \n",
       "3          3   ablaze           Morgantown, WV   \n",
       "4          4   ablaze                      NaN   \n",
       "...      ...      ...                      ...   \n",
       "11365  11365  wrecked  Blue State in a red sea   \n",
       "11366  11366  wrecked               arohaonces   \n",
       "11367  11367  wrecked                       ðŸ‡µðŸ‡­   \n",
       "11368  11368  wrecked           auroraborealis   \n",
       "11369  11369  wrecked                      NaN   \n",
       "\n",
       "                                                    text  target  \n",
       "0      Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1      Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2      Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3      Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4      \"Lord Jesus, your love brings freedom and pard...       0  \n",
       "...                                                  ...     ...  \n",
       "11365  Media should have warned us well in advance. T...       0  \n",
       "11366  i feel directly attacked ðŸ’€ i consider moonbin ...       0  \n",
       "11367  i feel directly attacked ðŸ’€ i consider moonbin ...       0  \n",
       "11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0  \n",
       "11369     Jake Corway wrecked while running 14th at IRP.       1  \n",
       "\n",
       "[11370 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import scikit-learn dataset library\n",
    "import pandas as pd\n",
    "\n",
    "#Text processing libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords') \n",
    "\n",
    "#sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "#Libraries for plotting\n",
    "import seaborn as sns\n",
    "#Load dataset\n",
    "df = pd.read_csv('tweets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5243689",
   "metadata": {},
   "source": [
    "## We have more targets with 0 that means no disaster and less targets 1 meaning disaster\n",
    "This could affect the resutls and accuracy in the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f54b009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='target'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df['target'].value_counts().index\n",
    "y = df['target'].value_counts()\n",
    "\n",
    "sns.barplot(x=x ,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c35c75",
   "metadata": {},
   "source": [
    "### We have a look on how does a Distaster and No Disaster Tweet looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6966334c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Asansol: A BJP office in Salanpur village was set ablaze last night. BJP has alleged that TMC is behind the incident. Police has bâ€¦'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we see how a Disaster tweet looks like (Target 1)\n",
    "disaster_tweets=df[df['target']==1]['text']\n",
    "disaster_tweets.values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22331fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Warm greetings to all on the occasion of #Lohri. As winter passes by may everyone's woes and troubles be set ablaze in tâ€¦\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we see how a non Disaster tweet looks like (Target 0)\n",
    "nondisaster_tweets=df[df['target']==0]['text']\n",
    "nondisaster_tweets.values[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0c8d5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    communal violence in bhainsa telangana stones ...\n",
       "1    telangana section  has been imposed in bhainsa...\n",
       "2             arsonist sets cars ablaze at dealership \n",
       "3            arsonist sets cars ablaze at dealership  \n",
       "4    lord jesus your love brings freedom and pardon...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Esta celda se va a quitar cuando estÃ© todo el cÃ³digo, estoy limpiando aqui para hacer el ejercicio\n",
    "# Applying a first round of text cleaning techniques\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "# Applying the cleaning function to both test and training datasets\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Let's take a look at the updated text\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab815560",
   "metadata": {},
   "source": [
    "### Tokenizing \n",
    "Now we have to tokenize each Tweet, this mean that we have to split each sentence in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18bc8c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [communal, violence, bhainsa, telangana, stone...\n",
       "1    [telangana, section, imposed, bhainsa, january...\n",
       "2           [arsonist, sets, cars, ablaze, dealership]\n",
       "3           [arsonist, sets, cars, ablaze, dealership]\n",
       "4    [lord, jesus, love, brings, freedom, pardon, f...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the dataset\n",
    "tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "df['text']=df['text'].apply(lambda x:tokenizer.tokenize(x))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f071c",
   "metadata": {},
   "source": [
    "###  Removing Stopwords\n",
    "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like, the, he, have etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fd7c1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[communal, violence, bhainsa, telangana, stone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[telangana, section, imposed, bhainsa, january...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>[arsonist, sets, cars, ablaze, dealership]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>[arsonist, sets, cars, ablaze, dealership]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lord, jesus, love, brings, freedom, pardon, f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword        location  \\\n",
       "0   0  ablaze             NaN   \n",
       "1   1  ablaze             NaN   \n",
       "2   2  ablaze   New York City   \n",
       "3   3  ablaze  Morgantown, WV   \n",
       "4   4  ablaze             NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  [communal, violence, bhainsa, telangana, stone...       1  \n",
       "1  [telangana, section, imposed, bhainsa, january...       1  \n",
       "2         [arsonist, sets, cars, ablaze, dealership]       1  \n",
       "3         [arsonist, sets, cars, ablaze, dealership]       1  \n",
       "4  [lord, jesus, love, brings, freedom, pardon, f...       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removing stopwords belonging to english language\n",
    "    \n",
    "    \"\"\"\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x : remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903cc07",
   "metadata": {},
   "source": [
    "### After the Stopwords we need to re join the whole text in to one string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fdc9dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>communal violence bhainsa telangana stones pel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telangana section imposed bhainsa january clas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>arsonist sets cars ablaze dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>arsonist sets cars ablaze dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lord jesus love brings freedom pardon fill hol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword        location  \\\n",
       "0   0  ablaze             NaN   \n",
       "1   1  ablaze             NaN   \n",
       "2   2  ablaze   New York City   \n",
       "3   3  ablaze  Morgantown, WV   \n",
       "4   4  ablaze             NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  communal violence bhainsa telangana stones pel...       1  \n",
       "1  telangana section imposed bhainsa january clas...       1  \n",
       "2               arsonist sets cars ablaze dealership       1  \n",
       "3               arsonist sets cars ablaze dealership       1  \n",
       "4  lord jesus love brings freedom pardon fill hol...       0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After preprocessing, the text format\n",
    "def combine_text(list_of_text):\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x : combine_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3e3f3",
   "metadata": {},
   "source": [
    "### Spliting the data to train the model\n",
    "We need to train our model with the same data set, but we need to assign in this case 80% to train and 20% of the same data to test it. This way we can see if the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fd26f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into independent and dependent features\n",
    "X=df['text']\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db26324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    communal violence bhainsa telangana stones pel...\n",
       "1    telangana section imposed bhainsa january clas...\n",
       "2                 arsonist sets cars ablaze dealership\n",
       "3                 arsonist sets cars ablaze dealership\n",
       "4    lord jesus love brings freedom pardon fill hol...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50497d",
   "metadata": {},
   "source": [
    "### Here the ```test_size=0.2``` means that we are going to take the 20% of the data to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ff61da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need data to train the model and data to test it. In this case we have 20% data to test\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "vectorizer=CountVectorizer()\n",
    "x_train_vectors=vectorizer.fit_transform(X_train)\n",
    "x_test_vectors=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7dc9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9981    breaking news us attorney general william barr...\n",
       "8767    photos taken iraq base us troops stationed sho...\n",
       "6900    ordinarily player would expected return presea...\n",
       "7068    countries treat taiwan partner issue reelected...\n",
       "8380    god storms patron house since left earth im go...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "083cdf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a matrix with all the words converted to numbers\n",
    "x_train_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002aa9e",
   "metadata": {},
   "source": [
    "### Now we can see the metrics of our model\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa080551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score train: 0.9478891820580475\n",
      "Accuracy score test 0.8698328935795955\n",
      "__________________________________________________\n",
      "\n",
      "-Classification report train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      7395\n",
      "           1       0.80      0.97      0.87      1701\n",
      "\n",
      "    accuracy                           0.95      9096\n",
      "   macro avg       0.89      0.95      0.92      9096\n",
      "weighted avg       0.96      0.95      0.95      9096\n",
      "\n",
      "-Classification report test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1861\n",
      "           1       0.61      0.77      0.68       413\n",
      "\n",
      "    accuracy                           0.87      2274\n",
      "   macro avg       0.78      0.83      0.80      2274\n",
      "weighted avg       0.89      0.87      0.88      2274\n",
      "\n",
      "Compute Area Under the Receiver Operating Characteristic Curve  train: 0.9545977607731045\n",
      "Compute Area Under the Receiver Operating Characteristic Curve test: 0.8309846693893908\n",
      "__________________________________________________\n",
      "\n",
      "Confusion Matrix Train:\n",
      " [[6980  415]\n",
      " [  59 1642]]\n",
      "Confusion Matrix Test:\n",
      " [[1660  201]\n",
      " [  95  318]]\n"
     ]
    }
   ],
   "source": [
    "clf_naive=MultinomialNB(alpha=0.2,fit_prior=False)\n",
    "clf_naive.fit(x_train_vectors,y_train)\n",
    "pred=clf_naive.predict(x_test_vectors)\n",
    "\n",
    "accuracy_score_train=metrics.accuracy_score(y_train,clf_naive.predict(x_train_vectors))\n",
    "print(f'Accuracy score train: {accuracy_score_train}')\n",
    "\n",
    "accuracy_score_test=metrics.accuracy_score(y_test,pred)\n",
    "print(f'Accuracy score test {accuracy_score_test}')\n",
    "print('_____'*10+'\\n')\n",
    "\n",
    "classification_report_train=metrics.classification_report(y_train,clf_naive.predict(x_train_vectors))\n",
    "print(f'-Classification report train:\\n {classification_report_train}')\n",
    "\n",
    "classification_report_test=metrics.classification_report(y_test,pred)\n",
    "print(f'-Classification report test:\\n {classification_report_test}')\n",
    "\n",
    "roc_auc_score_train=metrics.roc_auc_score(y_train,clf_naive.predict(x_train_vectors))\n",
    "print(f'Compute Area Under the Receiver Operating Characteristic Curve  train: {roc_auc_score_train}')\n",
    "\n",
    "roc_auc_score_test=metrics.roc_auc_score(y_test,pred)\n",
    "print(f'Compute Area Under the Receiver Operating Characteristic Curve test: {roc_auc_score_test}')\n",
    "\n",
    "print('_____'*10+'\\n')\n",
    "confusion_matrix_train=metrics.confusion_matrix(y_train,clf_naive.predict(x_train_vectors))\n",
    "print(f'Confusion Matrix Train:\\n {confusion_matrix_train}')\n",
    "\n",
    "confusion_matrix_test=metrics.confusion_matrix(y_test,pred)\n",
    "print(f'Confusion Matrix Test:\\n {confusion_matrix_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b213a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac4a50",
   "metadata": {},
   "source": [
    "At the beginning the train and test score seems to be near to 1 with a good accuracy. Then on the classification report we can see that the precision is overfitted on the class '0' and if we see the support column there is a huge difference between bot targets, we have 7935 tweets with 0 and 1701 with 1. This mean that the model data is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc48f91",
   "metadata": {},
   "source": [
    "https://muthu.co/understanding-the-classification-report-in-sklearn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c83e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
